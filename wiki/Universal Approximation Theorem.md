---
aliases:
  - 通用逼近定理
---

"Universal Approximation Theorem"（通用逼近定理）是神经网络理论中的一个重要定理。这个定理主要说明，一个前馈神经网络如果有足够的隐藏层和神经元，那么它可以逼近任何连续函数，无论这个函数有多复杂。

具体来说，这个定理表明，只要神经网络的激活函数（例如 sigmoid 函数或者 ReLU 函数）是非线性的，并且神经网络有足够的隐藏层和神经元，那么这个神经网络就可以逼近任何在闭集上定义的连续函数，只要这个闭集是**有限维欧几里得空间的子集**。

这个定理的一个重要应用是在深度学习中。由于深度神经网络可以逼近任何复杂的函数，因此它们可以用来学习和模拟各种复杂的数据模式，这使得深度学习在诸如图像识别、语音识别和自然语言处理等任务中表现出色。