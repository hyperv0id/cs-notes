## 2.1
> 数据集包含 1000 个样本，其中 500 个正例、500 个反例，将其划分为包含 70% 样本的训练集和 30% 样本的测试集用于留出法评估，试估算共有多少种划分方式.

$$
C_{500}^{350} \times C_{500}^{150}
$$


## 2.2
> 数据集包含 100 个样本，其中正、反例各一半，假定学习算法所产生的模型是将新样本预测为训练样本数较多的类别(训练样本数相同时进行随机猜测)，试给出用 10 折交叉验证法和留一法分别对错误率进行评估所得的结果.


**留一法**:
100%, 每次选择数量必不相同，选择更多的（相反）

**十折交叉验证**:
每组都有5个正例，5个反例，最后猜错的概率为 50%


## 2.3
> 若学习器 A 的 F1 值比学习器 B 高，试析 A 的 BEP 值是否也比 B 高.

$$
F_{1A} = \frac{2*BEP_A^2}{2 BEP_A} > 
F_{1B} = \frac{2*BEP_B^2}{2 BEP_B}
$$

$$
BEP_A > BEP_B
$$


## 2.4

> 试述真正例率 (TPR) 、假正例率 (FPR)与查准率 (P) 、查全率 (R)之间的联系.

1. $TPR = R$
2. 


## 2.5

> 试证明式 (2.22).

由[南瓜书](https://github.com/datawhalechina/pumpkin-book) 公式 2.20，可知 loss 为ROC曲线与y轴围成的面积，AUC为曲线与X轴围成的面积，那么显然和为1




## 2.6
> 试述错误率与 ROC 曲线的联系.

ROC曲线上每一个点都对应一个分类器的假/真正正例率，即对应一个错误率



## 2.7

> 试证明任意一条 ROC 曲线都有一条代价曲线与之对应，反之亦然.

TODO




## 2.8

> Min-max 规范化和公score 规范化是两种常用的规范化方法.令 z 和X' 分别表示变量在规范化前后的取值，相应的，令 $x_{min}$ 和 $x_{max}$即表示规范化前的最小值和最大值 ， $x_{bar}$ 和 $\sigma_x$ 表示规范化后的最小值和最大值，军和 σz 分别表示规范化前的均值和标准差，则 min-max 规范化、z-score 规范化分别如式 (2 .43)和 (2 .44)所示.试析二者的优缺点.

![](https://pic-1257412153.cos.ap-nanjing.myqcloud.com/images/images/2022/11/15/20221115165800-11e614.png)

min-max: 
- 如果分布不存在最大最小值就失效了
- 参考评委打分，受最值影响大

z-score: 

> 首先先要给数据做一个histogram，如果数据基本上满足高斯分布的话那么选择用Z-score Normalization。如果数据较为零散的话，可以选择Min-Max Scaling。
> 来自：[Min-Max Scale vs. Z-score Scale](https://blog.csdn.net/sdu_hao/article/details/104390269)



## 2.9

> 试述 $χ^2$ 检验过程.

TODO


## 2.10

> 试述在Friedman 检验中使用式 (2.34)与 (2.35) 的区别.


TODO



