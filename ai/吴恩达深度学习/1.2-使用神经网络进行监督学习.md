## 1.2 使用神经网络进行监督学习

监督学习的核心是通过带有标签的数据训练模型，使模型能预测新数据的输出。神经网络通过多层非线性变换，能够捕捉复杂特征，成为解决这类问题的重要工具。

### 网络结构与数据流动

神经网络包含输入层、隐藏层和输出层。输入层接收原始数据（如图像像素），隐藏层提取抽象特征，输出层生成预测结果。以下为典型结构示例：

![神经网络层次结构示意图：展示输入层、隐藏层与输出层的连接关系](http://assets.hypervoid.top/img/2025/04/01/image-20250401132137612-42a0.png)


### 训练流程与优化目标
训练过程涉及两个关键阶段：
1. **前向传播**：数据从输入层流向输出层，逐层计算激活值。例如，输出层对图像分类任务使用Softmax函数生成概率分布。
2. **反向传播**：通过损失函数（如交叉熵损失）计算预测误差，利用梯度下降算法调整网络权重，最小化预测误差。

| 组件   | 作用          | 示例               |
| ---- | ----------- | ---------------- |
| 损失函数 | 量化预测与真实值的差异 | 均方误差（回归）、交叉熵（分类） |
| 优化器  | 更新权重以降低损失   | SGD、Adam         |


### 典型应用场景

神经网络在处理高维非结构化数据时表现优异：

| 输入示例 | 输出形式  | 任务类型 | 模型                                                       |
| ---- | ----- | ---- | -------------------------------------------------------- |
| 房屋特征 | 价格    | 实体经济 | 多层[感知机](../待分类/感知机.md) (MLP) / 前馈神经网络 (FNN)              |
| 用户信息 | 广告投递  | 在线广告 | 深度因子分解机 (DeepFM) / Wide & Deep / MLP                     |
| 图像   | 标签    | 图像识别 | 卷积神经网络 ([CNN](../CNN.md))                                |
| 音频   | 字幕    | 音频识别 | 循环神经网络 ([RNN](../RNN.md)) / 长短期记忆网络 (LSTM) / Transformer |
| 某种语言 | 另一种语言 | 翻译   | Sequence-to-Sequence (Seq2Seq) / Transformer             |

### 挑战与改进方向
1. **数据需求**：深度网络需大量标注数据，小数据集易过拟合。
2. **计算成本**：训练大型模型需要高性能硬件支持。
3. **可解释性**：黑盒特性限制了在医疗等领域的应用，需结合注意力机制等可解释技术。

```mermaid
graph LR
A[数据准备] --> B[模型训练]
B --> C[验证调参]
C --> D[部署推理]
```

