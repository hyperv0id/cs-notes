## 对数几率 (Log-Odds)

**几率 (Odds):** 几率表示某个事件发生的概率与不发生的概率之比。
$$Odds = \frac{P(\text{事件发生})}{P(\text{事件不发生})} = \frac{p}{1 - p}$$
几率的取值范围是 $[0, +\infty)$。

**对数几率 (Log-Odds 或 Logit):** 对几率取自然对数 ($\ln$ 或 $\log$)。
$$Log-Odds = \log(Odds) = \log\left(\frac{p}{1 - p}\right)$$
对数几率的取值范围是 $(-\infty, +\infty)$。

**在逻辑回归中的作用:** 逻辑回归的核心思想是：**将线性组合 $z = \beta_0 + \beta_1 x_1 + ... + \beta_n x_n$ 直接建模为目标变量属于某个类别的**对数几率**。
$$\log\left(\frac{p}{1 - p}\right) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n$$
这个等式就是逻辑回归模型的基础。通过这个桥梁（对数几率），我们将一个具有无限取值范围的线性模型的输出，映射到了一个用于表示概率 ($p$) 的、介于 0 和 1 之间的量。Sigmoid 函数 $p = \frac{1}{1 + e^{-z}}$ 正是这个等式的逆运算，即由 $\log(p / (1 - p)) = z$ 反推出 $p$。

**统计学上的合理性 (广义线性模型 GLM)：**

- GLM 的思想是将响应变量（我们的目标变量）的**平均值**（对于伯努利分布，均值就是概率 $p$）通过一个**链接函数 (Link Function)** 与线性预测器 $\beta^Tx$ 关联起来。
- 对于二元分类问题，假设响应变量服从伯努利分布（Bernoulli Distribution）。伯努利分布的**规范链接函数 (Canonical Link Function)** 恰好就是**对数几率函数** ($\log(p / (1 - p))$)。
- 使用规范链接函数有许多优良的统计性质，例如可以简化最大似然估计 (Maximum Likelihood Estimation, MLE) 的过程，并保证参数估计的统计效率。简单来说，它使得找到最佳模型参数 $\beta$ 的优化问题更容易解决（通常是凸优化问题），能够找到全局最优解。

## 对数线性 (Log-Linear)

**含义:** "对数线性模型"是一个更广泛的概念，指的是模型中某个变量的**对数**与预测变量呈**线性关系**。

**与逻辑回归的关系:** 逻辑回归**可以被视为一种对数线性模型**，因为它建模的是**目标变量的对数几率**（即 $\log(p/(1-p))$）与特征的**线性组合**之间的关系。

**其他对数线性模型的例子:** 用于计数数据分析的泊松回归（Poisson Regression）也是一种对数线性模型，它建模的是目标变量的**期望值的对数**（$\log(E(y))$）与特征的**线性组合**之间的关系。

**总结:** 在你提到的上下文中，"对数线性"主要是指逻辑回归中，特征的线性组合与目标变量的对数几率之间存在的线性关系。它描述了模型在经过对数变换后的空间中的线性特性。